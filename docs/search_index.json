[["index.html", "C-Lock Application Program Interfaces 0.1 Abstract", " C-Lock Application Program Interfaces Authored by Drs. Jameson Brennan1, Ira Parsons1, Hector Menendez1, Meredith Harrison2 1South Dakota State University, Dept. of Animal Science, Rapid City SD 2C-Lock Inc. Rapid City SD 0.1 Abstract Advances in sensor technology have ushered in the ability to collect vast amounts of data in real-time for animal production systems. Though there is much promise in improving animal production and research utilizing precision systems, for this technology to be truly impactful, data generated needs to be accessed and processed in near real time for relevant decision-making. In this paper, three application programming interfaces were developed to facilitate near real-time data access. In addition, open-source tutorials were developed to generate summary statistics of three precision livestock technologies and systems checks to ensure equipment is working properly and animal adoption rates of technology are adequate for data collection. The development of data processing outlined in this paper will be essential for the successful implementation of precision technology and integration of data in real time with animal nutrition or decision-making algorithms (Brennan et al. 2024). "],["greenfeed-api.html", "1 GreenFeed API 1.1 API 1.2 Data Visualization", " 1 GreenFeed API Developed by Jameson Brennan, Ira Parsons, and Hector Menendez Department of Animal Science, South Dakota State University The objectives of this markdown document is to automate the download and visualization of Greenfeed data provided by C-Lock. Users will need to provide their own login credentials to run the code. This markdown can be used to quickly visualize usage of Greenfeed machines and preliminary data. knitr::opts_chunk$set(echo = TRUE) library(ggplot2) 1.1 API The first thing you need to do is to enter your variables for the code to run. In the quotations below you will need to change the username, password, FID (or greenfeed ID), and the start and end times for the data you want to download. Two things to note are 1) you can enter multiple greenfeeds assocated with an account and 2) the start time and end time must be in the same format. The chunk below sets the end time to the computer time for the most recent downloads. #change to login user name USER &lt;- &quot;username&quot; #Change to login password PASS &lt;- &#39;Password&#39; #Change to greenfeed id or id&#39;s. The second line can be uncommented out for multiple greenfeeds FID &lt;- &quot;541&quot; #FID &lt;- &quot;541,539,535,534&quot; #enter the start date (ST) and end date (ET) for the data you want to download ST &lt;- &quot;yyyy-mm-dd&quot; ET &lt;- &quot;yyyy-mm-dd&quot; 1.1.1 Data Download This code chunk will pull the data from the cloud based on the specifications of what was provided above. # Spaces must be replaced with %20 library(httr) # Must first install httr with: install.packages(&quot;httr&quot;) library(stringr) # First Authenticate to receive token: req &lt;- POST(&quot;https://portal.c-lockinc.com/api/login&quot;, body=list(user=USER, pass=PASS)) stop_for_status(req) TOK &lt;- trimws(content(req)) #URL=&quot;https://portal.c-lockinc.com/api/getemissions?d=visits&amp;fids=297,298&amp;st=2023-06-06%2000:00:00&amp;et=2023-06-14%2012:00:00&quot; # Now get data using the login token URL=paste0(&quot;https://portal.c-lockinc.com/api/getemissions?d=visits&amp;fids=&quot;, FID, &quot;&amp;st=&quot;, ST, &quot;&amp;et=&quot;, ET, &quot;%2012:00:00&quot;) req &lt;- POST(URL, body=list(token=TOK)) stop_for_status(req) a &lt;- content(req) #Split the lines perline &lt;- str_split(a, &quot;\\\\n&quot;)[[1]] #Split the commas into a dataframe, while getting rid of the &quot;Parameters&quot; line and the headers line df &lt;- do.call(&quot;rbind&quot;, str_split(perline[3:length(perline)], &quot;,&quot;)) df=as.data.frame(df) colnames(df)=c(&#39;FeederID&#39;,&#39;AnimalName&#39;,&#39;RFID&#39;,&#39;StartTime&#39;,&#39;EndTime&#39;,&#39;GoodDataDuration&#39;, &#39;CO2GramsPerDay&#39;,&#39;CH4GramsPerDay&#39;,&#39;O2GramsPerDay&#39;,&#39;H2GramsPerDay&#39;,&#39;H2SGramsPerDay&#39;, &#39;AirflowLitersPerSec&#39;,&#39;AirflowCf&#39;,&#39;WindSpeedMetersPerSec&#39;,&#39;WindDirDeg&#39;,&#39;WindCf&#39;, &#39;WasInterrupted&#39;,&#39;InterruptingTags&#39;,&#39;TempPipeDegreesCelsius&#39;,&#39;IsPreliminary&#39;,&#39;RunTime&#39;) 1.2 Data Visualization This next section is used to generate a series of quick plots to summarize visits and data from the greenfeeds to check usage rates. #convert start time to date df$Date=as.Date(df$StartTime) df$RFID=stringr:: str_sub(df$RFID,-6,-1) #get a count on the number of good observations by each greenfeed by day library(dplyr) daily_good_data=df %&gt;% count(FeederID, Date, sort = TRUE) daily_good_data=na.omit(daily_good_data) ggplot(daily_good_data,aes(x=Date,y=n))+ geom_bar(stat = &#39;identity&#39;)+ scale_x_date(breaks = &#39;2 day&#39;)+ facet_wrap(~FeederID)+ ggtitle(&#39;Number of good observations by GF by day&#39;)+ ylab(&#39;Number of daily observations&#39;)+ theme_light()+ theme(axis.text.x = element_text(angle = -45)) #get the number of unique animals visiting by day rfid_day=df %&gt;% # Applying group_by &amp; summarise group_by(Date,FeederID) %&gt;% summarise(count = n_distinct(RFID)) ## `summarise()` has grouped output by &#39;Date&#39;. You can override using the `.groups` argument. rfid_day=na.omit(rfid_day) ggplot(rfid_day,aes(x=Date,y=count))+ geom_bar(stat = &#39;identity&#39;)+ facet_wrap(~FeederID)+ scale_x_date(breaks = &#39;2 day&#39;)+ labs(title = &#39;Number of Unique animals per day&#39;)+ theme_light()+ theme(axis.text.x = element_text(angle = -45)) df=na.omit(df) df$CH4GramsPerDay=as.numeric(df$CH4GramsPerDay) ggplot(df,aes(y=CH4GramsPerDay,x=Date))+ geom_point(aes(color = RFID))+ geom_smooth(method = &#39;lm&#39;, se = F)+ ylim(0,300)+ labs(title = &#39;Grams CH4 per day, colors individual animals &#39;)+ theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = -45))+ theme_light() ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 11 rows containing non-finite outside the scale range (`stat_smooth()`). ## Warning: Removed 11 rows containing missing values or values outside the scale range (`geom_point()`). df %&gt;% filter(Date &gt; (max(df$Date) - 7)) %&gt;% dplyr::group_by(Date, RFID) %&gt;% dplyr::summarise(CH4GramsPerDay = mean(as.numeric(CH4GramsPerDay), na.rm = T)) %&gt;% ggplot(aes(x=Date,y=CH4GramsPerDay, fill = RFID))+ geom_boxplot()+ # facet_wrap(~Assignment)+ theme_classic()+ theme(panel.grid.major = element_line(color = &#39;black&#39;, linewidth = 0.1), panel.grid.minor = element_line(color = &#39;grey&#39;, linewidth = 0.05), axis.text.x = element_text(angle = 45, hjust = 1), plot.caption = element_text(hjust = 0), legend.position = &quot;right&quot;) ## `summarise()` has grouped output by &#39;Date&#39;. You can override using the `.groups` argument. "],["smartscale-api.html", "2 SmartScale API 2.1 API 2.2 Data Processing 2.3 Data Visualization 2.4 Animal Performance", " 2 SmartScale API Developed by Jameson Brennan, Ira Parsons, and Hector Menendez Department of Animal Science, South Dakota State University The objectives of this hands on tutorial are to introduce workshop participants to methods for streamlining SmartScale data processing tasks in R. 2.1 API 2.1.1 Libraries Our first step to processing the data is to import the libraries we will use to run our analysis. Each library contains a set of functions which can be used to process data. For example, the function mean() would sum the values in a column and divide by the number of observations in the column. This code will look to see if the necessary packages are installed on your computer and if not install and load them. ##if there is an error and a package or dependency needs to be updated un-comment the #code below and replace &#39;rvest&#39; with package #remove.packages(&#39;rvest&#39;) #install.packages(&#39;rvest&#39;) #Needed packages list.of.packages &lt;- c(&quot;rvest&quot;,&#39;tidyverse&#39;,&#39;data.table&#39;,&#39;lubridate&#39;, &#39;knitr&#39;,&#39;markdown&#39;,&#39;fasttime&#39;,&#39;MASS&#39;) new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages) library(rvest) library(tidyverse) library(data.table) library(lubridate) library(knitr) library(rmarkdown) library(fasttime) library(MASS) 2.1.2 Login Variables The first thing you need to do is to enter your variables for the code to run. In the quotations below you will need to change the username, password, FID (or SmartScale ID), and the start and end times for the data you want to download. Two things to note are 1) you can enter multiple greenfeeds assocated with an account and 2) the start time and end time must be in the same format. The chunk below sets the end time to the computer time for the most recent downloads. #change to login user name USERNAME &lt;- &#39;demo_user&#39; #Change to login password PASSWORD &lt;- &#39;greenfeed&#39; #Change SmartScale id or id&#39;s. The second line can be uncommented out for multiple #SmartScales notice there is no space between commas for the multiple id&#39;s SmartScale_ID &lt;- &#39;1000119&#39; #SmartScale_ID &lt;- &quot;1000119,1000121,1000132&quot; #enter the start date (ST) and end date (ET) for the data you want to download date.start &lt;- &#39;2023-03-14&#39; date.end &lt;- &#39;2023-06-01&#39; ## Data parameters ----- FULL_WEIGHT &lt;- 1 # 1 for full body weight calculated using C-Lock algorithm, 0 for raw #half-body weights, full weights calculated by taking the front end weight * 1.76 GET_VISITS &lt;- 1 #Put 1 to get individual visits, Put 0 to get daily averages 2.1.3 Data Download This code chunk will pull the data from the cloud based on the specifications of what was provided above. # Local system setup ---- ## Choose a temp folder to download the CSV to ---- if(Sys.info()[&quot;sysname&quot;] == &quot;Darwin&quot;){ TEMP_DIRECTORY &lt;- &quot;/tmp&quot; #For Mac or Linux }else{ TEMP_DIRECTORY &lt;- &quot;.&quot; #For Windows (Maybe put C:\\Users\\yourusername\\Desktop) } ## Load required libraries ---- suppressWarnings(suppressMessages(try(require(rvest), silent = TRUE))) suppressWarnings(suppressMessages(try(require(httr), silent = TRUE))) suppressWarnings(suppressMessages(try(require(RCurl), silent = TRUE))) ## Login URL ----- login_url &lt;- &quot;https://greenfeed.c-lockinc.com/GreenFeed/checklogon.php&quot; ## API URL ----- if (GET_VISITS == GET_VISITS) { #Download URL - Individual Visits Weights download_url &lt;- paste0(&quot;https://greenfeed.c-lockinc.com/GreenFeed/tabledata/sfanimals/getanimalweightdetails.php?dl=1&quot;, &quot;&amp;fids=0,&quot;, SmartScale_ID, &quot;&amp;st=&quot;, date.start, &quot;&amp;et=&quot;, date.end, &quot;&amp;full=&quot;, FULL_WEIGHT); } else { #Download URL - Daily Average Weights download_url &lt;- paste0(&quot;https://greenfeed.c-lockinc.com/GreenFeed/tabledata/sfanimals/animalweights.php?dl=1&amp;summary=0&quot;, &quot;&amp;fids=0,&quot;, SmartScale_ID, &quot;&amp;from=&quot;, date.start0, &quot;&amp;to=&quot;, date.end, &quot;&amp;full=&quot;, FULL_WEIGHT); } # Download data ---- ## Log into the website using URL requests ----- { #Create session then download form data session &lt;- session(&quot;https://greenfeed.c-lockinc.com/GreenFeed&quot;) form &lt;- html_form(read_html(login_url))[[1]] #Set login credentials form &lt;- set_values(form, username = USERNAME) form &lt;- set_values(form, password = PASSWORD) suppressWarnings(form &lt;- set_values(form, redir = &quot;home.php?logout&quot;)) #This will give you a warning - we can hide it with suppressWarnings #Save main page url suppressMessages(main_page &lt;- submit_form(session, form)) #Download the data download &lt;- jump_to(main_page, download_url) } # Decode binary data ---- #Because the downloaded data is binary data, you must write it to a temporary file then read it back as a CSV. ## Write data to a file ---- FILENAME &lt;- paste0(TEMP_DIRECTORY, &quot;/C.txt&quot;) writeBin(download$response$content, FILENAME) #Read the CSV into a df dataframe if (GET_VISITS == 1) { #SmartScale Headers are: &quot;Link&quot; &quot;StartTime&quot; &quot;StopTime&quot; &quot;FeederID&quot; &quot;Duration&quot; &quot;AnimalName&quot; &quot;RFIDTag&quot; &quot;Weight&quot; &quot;Valid&quot; colclasses=c(&quot;character&quot;, &quot;POSIXct&quot;, &quot;POSIXct&quot;, &quot;integer&quot;, &quot;integer&quot;, &quot;character&quot;, &quot;character&quot;, &quot;integer&quot;, &quot;character&quot;); } else { #SmartScale Headers are: &quot;Link&quot; &quot;StartTime&quot; &quot;StopTime&quot; &quot;FeederID&quot; &quot;Duration&quot; &quot;AnimalName&quot; &quot;RFIDTag&quot; &quot;Weight&quot; &quot;Valid&quot; colclasses=c(&quot;character&quot;, &quot;character&quot;); } d.smart = fread(file = FILENAME, header=TRUE, sep=&quot;,&quot;, quote=&quot;\\&quot;&quot;, colClasses = colclasses) # Read into data.table d.smart[d.smart == 0] &lt;- NA # Replace 0&#39;s with NA 2.2 Data Processing This is the raw dataset downloaded from the SmartScale API.The code chunk will print the first five rows of data in table format. knitr::kable( head(d.smart)) View StartTime StopTime FeederID Duration AnimalName RFIDTag Weight Valid https://greenfeed.c-lockinc.com/GreenFeed/sfdata.php?fid=1000119&amp;dt=2023-03-14%2018:47:22&amp;dur=60&amp;s1=20&amp;s2=23 2023-03-14 18:47:32 2023-03-14 18:48:05 1000119 33 SHSF K30 000000000840003241679559 1233 https://greenfeed.c-lockinc.com/GreenFeed/sfdata.php?fid=1000119&amp;dt=2023-03-14%2019:30:08&amp;dur=60&amp;s1=20&amp;s2=23 2023-03-14 19:30:18 2023-03-14 19:30:34 1000119 16 SHSF K41 000000000840003241679563 1080 https://greenfeed.c-lockinc.com/GreenFeed/sfdata.php?fid=1000119&amp;dt=2023-03-14%2019:30:27&amp;dur=60&amp;s1=20&amp;s2=23 2023-03-14 19:30:37 2023-03-14 19:30:55 1000119 18 SHSF K41 000000000840003241679563 1072 https://greenfeed.c-lockinc.com/GreenFeed/sfdata.php?fid=1000119&amp;dt=2023-03-14%2019:30:57&amp;dur=60&amp;s1=20&amp;s2=23 2023-03-14 19:31:07 2023-03-14 19:31:20 1000119 13 SHSF K41 000000000840003241679563 703 No https://greenfeed.c-lockinc.com/GreenFeed/sfdata.php?fid=1000119&amp;dt=2023-03-14%2020:01:56&amp;dur=60&amp;s1=20&amp;s2=23 2023-03-14 20:02:06 2023-03-14 20:02:22 1000119 16 SHSF K41 000000000840003241679563 1092 https://greenfeed.c-lockinc.com/GreenFeed/sfdata.php?fid=1000119&amp;dt=2023-03-14%2020:08:08&amp;dur=60&amp;s1=20&amp;s2=23 2023-03-14 20:08:18 2023-03-14 20:08:30 1000119 12 Beach K224 000000000840003241679593 772 No We can see that the ‘view’ column is likely not necessary and can be removed. In addition, we will create a new column called ‘Date’ that converts the start time to a Date only value. Lastly we will convert the 14 digit RFID number to only the last 6 digits to simplify identifying unique animals. #Remove unnecessary columns d.smart$View=NULL #convert date time to date value to look at daily visits d.smart$Date=as.Date(d.smart$StartTime) d.smart$RFIDTag= stringr:: str_sub(d.smart$RFIDTag,-6,-1) #get last 6 digits of RFID One of the first steps to processing and cleaning data is to plot it. This code chunk will get the number of daily visits for each scale and plot it by day. 2.3 Data Visualization This next section is used to generate a series of quick plots to summarize visits and data from the SmartScales to check usage rates. This can be helpful to plot is animals are routinely using the equipment and to see if there are any sudden changes in usage rate that may indicate either a issue with the technology or access. #get the number of unique animals visiting by day rfid_day=d.smart %&gt;% # Applying group_by &amp; summarise group_by(Date,FeederID) %&gt;% summarise(count = n_distinct(RFIDTag)) rfid_day=na.omit(rfid_day) ggplot(rfid_day,aes(x=Date,y=count))+ geom_bar(stat = &#39;identity&#39;)+ facet_wrap(~FeederID)+ ggtitle(&#39;Number of Unique animals per day&#39;) #convert start time to date d.smart$Date=as.Date(d.smart$StartTime) d.smart$RFID=stringr:: str_sub(d.smart$RFID,-6,-1) #get a count on the number of good observations by each greenfeed by day library(dplyr) daily_good_data=d.smart %&gt;% count(FeederID, Date, sort = TRUE) daily_good_data=na.omit(daily_good_data) ggplot(daily_good_data,aes(x=Date,y=n))+ geom_bar(stat = &#39;identity&#39;)+ facet_wrap(~FeederID)+ ggtitle(&#39;Number of observations by SmartScale by day&#39;)+ ylab(&#39;Number of daily observations&#39;) The smartscale data has a column named ‘Valid’ that flags potentially bad data in the system based on quantiles. The following plots show the bad data labeled as Valid = No for the entire dataset and for an individual animal. #plot animal weight by date ggplot(d.smart,aes(x=Date,y=Weight,color=Valid))+ geom_point() ggplot(subset(d.smart,RFIDTag==&#39;679563&#39;),aes(x=Date,y=Weight,color=Valid))+ geom_point() This next chunk of code will remove the observations that are not valid and replot the data. #Remove not valid points d.smart=subset(d.smart,Valid!=&#39;No&#39;) #plot animal weight by date ggplot(d.smart,aes(x=Date,y=Weight))+ geom_point() 2.3.1 Further Data Cleaning and Filtering This next code chunk will add day of trial to the dataframe which will help for calculating average daily gain (ADG) # Add days to data d.tdays = data.table(Date = seq.Date(from = as.Date(min(d.smart$Date)), to = as.Date(max(d.smart$Date)), by = 1), tday = as.numeric(seq(from = 0, to = difftime(max(d.smart$Date), min(d.smart$Date), units = &quot;days&quot;)))) d.smart = d.tdays[d.smart, on = &#39;Date&#39;] d.smart[, Weight:= as.numeric(Weight)] d.smart[, RFIDTag := as.character(RFIDTag)] In addition to flagging the data as valid or not valid, Parsons et al., 2023 proposed an additional method using robust regression to remove potentially bad data from in pasture weighing systems. We will apply that method below (Parsons et al. 2023). # Filter Spurious weights using robust regression (Parsons et al., 2023) m.rob = rlm(Weight ~ RFIDTag + tday, data = d.smart) d.smrtrob = data.table(FeederID = d.smart$FeederID, RFIDTag = d.smart$RFIDTag, Date = d.smart$Date, tday = d.smart$tday, StartTime = d.smart$StartTime, Duration = d.smart$Duration, Weight = d.smart$Weight, resid = m.rob$residuals, hwt = m.rob$w) ## Assign outliers d.smrtrob[, Outlier := fifelse(hwt &gt; 0.99, &#39;In Range&#39;,&#39;Outlier&#39;)] ggplot(subset(d.smrtrob,RFIDTag==&#39;679563&#39;),aes(x=Date,y=Weight,color=Outlier))+ geom_point() d.smart = d.smrtrob[Outlier == &#39;In Range&#39;, ] # Filter to in range points Using the table function we will get the number of daily weights for each individual animal. We can see that several tags only have a few observations while others have hundreds. These are could be test tags that were used to test the scales or had animals that infrequently used the equipement. The code below will delete individual tags with less than 6 observations. table(d.smart$RFIDTag) ## ## 030197 030226 030296 030312 605891 605892 605893 605896 605899 679558 679559 679560 679563 679572 679573 679590 679591 679593 ## 6 1 2 1 242 255 365 354 326 281 242 243 337 70 57 400 231 229 ## 679594 679596 679605 679608 679612 679617 679619 679622 679629 679633 679635 679663 679795 679814 679817 679822 680396 680410 ## 340 318 132 333 144 337 338 212 175 241 293 2 4 2 6 2 243 260 ## 680411 680412 680413 680414 828028 828031 828038 ## 334 257 269 305 216 296 340 d.smart=d.smart %&gt;% group_by(RFIDTag) %&gt;% filter(n()&gt;= 6) %&gt;% ungroup() table(d.smart$RFIDTag) ## ## 030197 605891 605892 605893 605896 605899 679558 679559 679560 679563 679572 679573 679590 679591 679593 679594 679596 679605 ## 6 242 255 365 354 326 281 242 243 337 70 57 400 231 229 340 318 132 ## 679608 679612 679617 679619 679622 679629 679633 679635 679817 680396 680410 680411 680412 680413 680414 828028 828031 828038 ## 333 144 337 338 212 175 241 293 6 243 260 334 257 269 305 216 296 340 2.4 Animal Performance Next we want to calculate the average daily gain. To do so we can fit a linear regression to get a model for to estimate weight by day of trial. If we wanted to fit a linear model to the entire herd we can do so using all available data with Weight as our y and trial day as our x. The code below fits this linear model. model_all_animals=lm(Weight~tday,data=d.smart) summary(model_all_animals) ## ## Call: ## lm(formula = Weight ~ tday, data = d.smart) ## ## Residuals: ## Min 1Q Median 3Q Max ## -336.93 -51.31 -8.48 62.83 377.41 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.183e+03 1.883e+00 628.0 &lt;2e-16 *** ## tday 4.342e+00 4.207e-02 103.2 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 88.14 on 9025 degrees of freedom ## Multiple R-squared: 0.5414, Adjusted R-squared: 0.5414 ## F-statistic: 1.065e+04 on 1 and 9025 DF, p-value: &lt; 2.2e-16 We can see that the intercept of the model is 536, which would equate to our average starting weight for the herd and the slope is 1.96 which would equate to our average daily gain (ADG). Plotting it we can see the relationship. ggplot(d.smart,aes(y=Weight,x=tday))+ geom_point()+ geom_smooth(method=lm) Though herd level ADG is important, using precision data we can also look at individual animal ADG. To do so we need to run a linear model for each individual animal. The code below will loop through each individual animal, subset the data based on RFID tag, create a linear model as above, extract the slope and intercept for the model, and save them in a new dataframe that contains the RFIDtag, slope, and intercept for each individual animal. ADG_individual=data.frame() for (i in 1:length(unique(d.smart$RFIDTag))){ sublm=subset(d.smart,RFIDTag==unique(d.smart$RFIDTag)[i]) mod=lm(sublm$Weight~sublm$tday) int= mod$coefficients[1] slope=mod$coefficients[2] sub_df=data.frame(unique(sublm$RFIDTag),int,slope) ADG_individual=rbind(ADG_individual,sub_df) } row.names(ADG_individual) &lt;- NULL Plotting the data we can see the slope and intercept for each animal with the RFID tag. colnames(ADG_individual)=c(&#39;RFIDTag&#39;,&#39;Intercept&#39;,&#39;Slope&#39;) ggplot(ADG_individual,aes(x=Intercept,y=Slope,label=RFIDTag))+ geom_point(size=2,color=&#39;Red&#39;)+ geom_text(hjust=0, vjust=0)+ ggtitle(&#39;ADG and Starting Weight for Individual Animals&#39;)+ xlab(&quot;\\nStarting Weight (Intercept) in Lbs&quot;)+ ylab(&#39;ADG (Slope) in Lbs \\n&#39;) "],["smartfeeder-api.html", "3 SmartFeeder API 3.1 API 3.2 SmartFeeder Data Processing 3.3 SmartFeedert Data Visualization", " 3 SmartFeeder API Developed by Jameson Brennan, Ira Parsons, and Hector Menendez Department of Animal Science, South Dakota State University The objectives of this hands on tutorial are to introduce workshop participants to methods for streamlining SmartFeeder data processing tasks in R. 3.1 API 3.1.1 Libraries Our first step to processing the data is to import the libraries we will use to run our analysis. Each library contains a set of functions which can be used to process data. For example, the function mean() would sum the values in a column and divide by the number of observations in the column. This code will look to see if the necessary packages are installed on your computer and if not install and load them. ##if there is an error and a package or dependency needs to be updated un-comment the #code below and replace &#39;rvest&#39; with package #remove.packages(&#39;rvest&#39;) #install.packages(&#39;rvest&#39;) #Needed packages list.of.packages &lt;- c(&quot;rvest&quot;,&#39;httr&#39;,&#39;RCurl&#39;,&#39;tidyverse&#39;,&#39;data.table&#39;,&#39;lubridate&#39;, &#39;knitr&#39;,&#39;markdown&#39;,&#39;fasttime&#39;,&#39;MASS&#39;) new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages) library(rvest) library(httr) library(RCurl) library(tidyverse) library(data.table) library(lubridate) library(knitr) library(rmarkdown) library(fasttime) library(MASS) 3.1.2 Login credentials Next, we need to create character variables specifying the login credentials for the application interface. In the quotations, enter your username and password. #change to login user name USERNAME &lt;- &#39;demo_user&#39; #Change to login password PASSWORD &lt;- &#39;greenfeed&#39; 3.1.3 Report paramters The next step is to enter the parameters for our data query.In the quotations below you will need to change the FID (or SmartFeeder ID), and the start and end times for the data you want to download. Two things to note are 1) you can enter multiple pieces of equipment assocated with an account and 2) the start time and end time must be in the same format. We have entered an end time since our data collection for this project is complete. However, you can change this parameter to current computer time to download the most recent dataset. ## Equipment assignments ----- equipIDs = c(&#39;10818,10819,10820,10821,10822&#39;) intake.type = &#39;visits&#39; # Type of data requested ## Date start and end ----- date.start &lt;- as.POSIXct(&#39;2023-03-14&#39;, format = &#39;%Y-%m-%d&#39;, tz = &#39;UTC&#39;) date.end &lt;- as.Date(&#39;2023-07-18&#39;,format = &#39;%Y-%m-%d&#39;, tz = &#39;UTC&#39;) 3.1.4 Data Download This code chunk will pull the data from the cloud based on the specifications of what was provided above. # Login ---- # First Authenticate to receive token: req &lt;- POST(&quot;https://portal.c-lockinc.com/api/login&quot;, body=list(user=USERNAME, pass=PASSWORD)) stop_for_status(req) TOK &lt;- trimws(content(req)) # Set up URL ---- url = paste0(&#39;https://portal.c-lockinc.com/api/&#39;, &#39;getintake?d=&#39;,intake.type, # Specify vists or daily average &#39;&amp;fids=&#39;,equipIDs, # Specify feeder ids &#39;&amp;st=&#39;,date.start, # Specify start date &#39;&amp;et=&#39;,date.end # Specify end date ) # Download data ---- req = POST(url,body = list(token=TOK)) stop_for_status(req) # Parse data ---- ct = str_split(content(req, as = &#39;text&#39;), &#39;\\\\n&#39;)[[1]] d.sfeed = data.table(do.call(&#39;rbind&#39;, str_split(ct[3:length(ct)],&quot;,&quot;))) colnames(d.sfeed) = c(str_split(ct[2],&#39;,&#39;)[[1]]) 3.2 SmartFeeder Data Processing This is the raw dataset downloaded from the SmartFeeder API.The code chunk will print the first five rows of data in table format. knitr::kable(head(d.sfeed)) FeederID RFID StartTime EndTime Duration StartMassKG EndMassKG IntakeKG FeedTypeNum WarningCode WarningMsg SSFTray 10818 000000000840003252605896 2023-03-14 18:00:29 2023-03-14 18:02:42 133 121.708 121.222 0.486 1 0 0 10818 000000000840003252605892 2023-03-14 18:08:33 2023-03-14 18:21:39 786 121.247 118.65 2.597 1 0 0 10818 000000000840003252605896 2023-03-14 18:21:39 2023-03-14 18:28:08 389 118.65 118.199 0.45 1 0 0 10818 2023-03-14 18:28:08 2023-03-14 18:58:44 1836 118.199 114.214 3.986 1 3 Unallocated feed. 0 10818 000000000840003241679559 2023-03-14 18:58:44 2023-03-14 19:05:44 420 114.214 113.067 1.146 1 0 0 10818 000000000840003241679617 2023-03-14 19:05:44 2023-03-14 19:09:48 244 113.067 111.937 1.131 1 0 0 We can see that the ‘SSFTray’ column is likely not necessary and can be removed. In addition, we will create a new column called ‘Date’ that converts the start time to a Date only value. Lastly we will convert the 14 digit RFID number to only the last 6 digits to simplify identifying unique animals. #Remove unnecessary columns d.sfeed$SSFTray=NULL #convert date time to date value to look at daily visits d.sfeed$Date=as.Date(d.sfeed$StartTime) d.sfeed$RFIDTag= stringr:: str_sub(d.sfeed$RFID,-6,-1) #get last 6 digits of RFID 3.3 SmartFeedert Data Visualization One of the first steps to processing and cleaning data is to plot it. This code chunk will get the number of daily visits for each feeder and plot it by day. The smartfeeder data has a column named ‘Valid’ that flags potentially bad data in the system based on quantiles. The following plots show the bad data labeled as Valid = No for the entire dataset and for an individual animal. # Plot warnings d.sfeed %&gt;% dplyr::filter(RFID==&#39;000000000840003252605896&#39; &amp; WarningMsg != &quot;&quot;) %&gt;% group_by(Date,WarningMsg) %&gt;% mutate(Count = n()) %&gt;% ggplot(aes(x=Date, y = Count, fill=WarningMsg))+ geom_col() This next session shows a few examples of quickly calculating animal behavior to summarize daily animal visit behavior to quickly observe utilization rates. These plots are helpful to ensure equipment is functioning as expected, and that animals are using the equipment as desired. # FeedingBehavior ----- d.fbdaily = d.sfeed[, .(BVfreq = .N, BVdur.tot = sum(as.numeric(Duration), na.rm = T), BVdur.u = mean(as.numeric(Duration), na.rm = T), BVdur.sd = sd(as.numeric(Duration), na.rm = T), IntakeKG.tot = sum(as.numeric(IntakeKG), na.rm = T), ERkg.min = (sum(as.numeric(IntakeKG), na.rm = T)/(sum(as.numeric(Duration), na.rm = T)/60))), by = list(RFID,Date)] # Calculate cumulative intake setorder(d.fbdaily, cols = &#39;RFID&#39;,&#39;Date&#39;) d.fbdaily[, cumDMI := cumsum(IntakeKG.tot), by = &#39;RFID&#39;] Now, we have applied processing algorithms to calculate animal feeding behaviors, including feed intake. Next, we can quickly plot some of these behaviors. p.bvfreq = d.fbdaily %&gt;% dplyr::filter(RFID %in% c(&#39;000000000840003241680417&#39;, &#39;000000000840003241679459&#39;, &#39;000000000840003241679471&#39;)) %&gt;% ggplot(aes(as.Date(Date), y = BVfreq))+ geom_point(aes(color = RFID))+ geom_smooth(aes(color = RFID), se = F)+ geom_smooth(se = F)+ labs(x = &#39;Date&#39;, y = &#39;Bunk visit frequency, n per day&#39;, title = &#39;Bunk visit frequency&#39;)+ theme_classic()+ theme(panel.grid.major = element_line(color = &#39;black&#39;, size = 0.1), panel.grid.minor = element_line(color = &#39;grey&#39;, size = 0.05), axis.text.x = element_text(angle = 45, hjust = 1), plot.caption = element_text(hjust = 0), legend.position = &quot;bottom&quot;) p.bvfreq ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; This next chunk of code will remove the observations that are not valid and replot the data. #Remove not valid points d.sfeed=subset(d.sfeed, WarningMsg == &quot;&quot;) # FeedingBehavior ----- d.fbdaily = d.sfeed[, .(BVfreq = .N, BVdur.tot = sum(as.numeric(Duration), na.rm = T), BVdur.u = mean(as.numeric(Duration), na.rm = T), BVdur.sd = sd(as.numeric(Duration), na.rm = T), IntakeKG.tot = sum(as.numeric(IntakeKG), na.rm = T), ERkg.min = (sum(as.numeric(IntakeKG), na.rm = T)/(sum(as.numeric(Duration), na.rm = T)/60))), by = list(RFID,Date)] # Calculate cumulative intake setorder(d.fbdaily, cols = &#39;RFID&#39;,&#39;Date&#39;) d.fbdaily[, cumDMI := cumsum(IntakeKG.tot), by = &#39;RFID&#39;] #plot animal weight by date p.intakedaily = d.fbdaily %&gt;% dplyr::filter(RFID %in% c(&#39;000000000840003241680417&#39;, &#39;000000000840003241679459&#39;, &#39;000000000840003241679471&#39;)) %&gt;% ggplot(aes(x = as.Date(Date), y = IntakeKG.tot, color = RFID))+ geom_point()+ geom_smooth(se = F)+ labs(x = &#39;Date&#39;, y = &#39;Daily intake, kg per day&#39;, title = &#39;Intake&#39;)+ theme_classic()+ theme(panel.grid.major = element_line(color = &#39;black&#39;, size = 0.1), panel.grid.minor = element_line(color = &#39;grey&#39;, size = 0.05), axis.text.x = element_text(angle = 45, hjust = 1), plot.caption = element_text(hjust = 0), legend.position = &quot;none&quot;) p.intakedaily ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; # Cumulate daily intake ----- d.sfeed ## FeederID RFID StartTime EndTime Duration StartMassKG ## &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; ## 1: 10818 000000000840003252605896 2023-03-14 18:00:29 2023-03-14 18:02:42 133 121.708 ## 2: 10818 000000000840003252605892 2023-03-14 18:08:33 2023-03-14 18:21:39 786 121.247 ## 3: 10818 000000000840003252605896 2023-03-14 18:21:39 2023-03-14 18:28:08 389 118.65 ## 4: 10818 000000000840003241679559 2023-03-14 18:58:44 2023-03-14 19:05:44 420 114.214 ## 5: 10818 000000000840003241679617 2023-03-14 19:05:44 2023-03-14 19:09:48 244 113.067 ## --- ## 132895: 10822 000000000840003241679458 2023-07-17 20:22:54 2023-07-17 20:26:41 227 30.739 ## 132896: 10822 000000000840003241679454 2023-07-17 20:26:41 2023-07-17 20:29:55 194 30.31 ## 132897: 10822 000000000840003241679450 2023-07-17 20:30:24 2023-07-17 20:34:13 229 29.8 ## 132898: 10822 000000000840003241679452 2023-07-17 20:35:02 2023-07-17 20:44:16 554 29.223 ## 132899: ## EndMassKG IntakeKG FeedTypeNum WarningCode WarningMsg Date RFIDTag ## &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;char&gt; &lt;Date&gt; &lt;char&gt; ## 1: 121.222 0.486 1 0 2023-03-14 605896 ## 2: 118.65 2.597 1 0 2023-03-14 605892 ## 3: 118.199 0.45 1 0 2023-03-14 605896 ## 4: 113.067 1.146 1 0 2023-03-14 679559 ## 5: 111.937 1.131 1 0 2023-03-14 679617 ## --- ## 132895: 30.31 0.429 1 0 2023-07-17 679458 ## 132896: 29.8 0.51 1 0 2023-07-17 679454 ## 132897: 29.177 0.623 1 0 2023-07-17 679450 ## 132898: 29.101 0.123 1 0 2023-07-17 679452 ## 132899: &lt;NA&gt; d.PrevDayFE = d.sfeed[Date == as.character(&#39;2023-07-01&#39;) &amp; RFID %in% c(&#39;000000000840003241680417&#39;, &#39;000000000840003241679459&#39;, &#39;000000000840003241679471&#39;),] d.PrevDayFE[, DaySec := hour(StartTime)*3600 + minute(StartTime)*60 + second(StartTime)] setorder(d.PrevDayFE,cols = &#39;RFID&#39;,&#39;DaySec&#39;) d.PrevDayFE[, cumDMI := cumsum(IntakeKG), by = &#39;RFID&#39;] p.CumIntakeDaily = d.PrevDayFE %&gt;% ggplot(aes(x = as.POSIXct(StartTime), y = cumDMI,color = RFID))+ geom_point()+ geom_line()+ scale_x_datetime(date_labels = &quot;%H:%M&quot;)+ # facet_wrap(~RFID, scales = &#39;free&#39;)+ labs(x = &#39;Time, hour&#39;, y = &#39;Cumulative Intake, kg&#39;)+ theme_classic()+ theme(panel.grid.major = element_line(color = &#39;black&#39;, size = 0.1), panel.grid.minor = element_line(color = &#39;grey&#39;, size = 0.05), axis.text.x = element_text(angle = 45, hjust = 1), plot.caption = element_text(hjust = 0), legend.position = &quot;none&quot;) p.CumIntakeDaily "],["automating-api-reports.html", "4 Automating API Reports", " 4 Automating API Reports As demonstrated above, API’s allow routine and replicate access to online databases, making them extremely useful for integrating sensor systems via the internet of things infrastructure. Automated reports are a means of realizing and testing the true value of real-time data. Creating automated reports that land in your inbox serve as a way for scientists to realize the value of real-time data, and spark the creative juices to begin data analysis as the data comes in. And, on a more mundane but perhaps more importantly, it serves to improve project and equipment management by providing detailed reports for graduate students, advisors, and research managers to use to monitor precision livestock equipment, and fix issues in real-time as they arise. Creating the report Create the report by following many of the same steps you would normally use to learn about your data at the beginning of any data analysis project. These steps are already given in the previous examples. After cleaning your data, organize the plots and information into a coherent report using Rmarkdown. This document allows combining data and writing, making it a simple solution to automate various data wrangling, processing, and reporting tasks. Sending the report to yourself Now that you have the report created, wouldn’t it be great to get it in your inbox, on your phone, or wherever was most convenient, daily? This would save you the time to start up your computer program and rerun daily reports. I automated my reports utilizing the Blastula package and a dumby gmail account. 1) First, create an r script to knit the markdown document. + I included a couple of libraries statements, + Set up the system environment pointing to where my pandoc tools are installed (google this) + Specify the working directory where my code, files storing the data, and markdown files live + Finally, include the blastula code that renders an email from the rmarkdown document, and sends it using my gmail credentials. These email keys are protected text files downloaded from your dumby gmail account, and basically are what blastula uses to login and send your email message automatically Next, we need to program the computer to tell it to automatically push “RUN” on your R script. To do this we will use a .bat (microsofts term for a batch) file. For those computer nerds among us, this is quite simple. Those who are just into R programing, this is a bit intimidating. But never fear, it is acually quite simple. Create a simple text file using notepad on any windows computer TITLE names the code, but this isn’t important :: comments out sections, similar to the # in R programing languange define the path to your R program using the “set” command. Typically R will live in your computers program files on the C drive. This creates a command, named rscript that tells the computer to open R. Next, define the path to the .R code we created in step 1, again using the “set” command. This creates a second command to open the r code, named rungf to run the gf feed code in the R environment created in the rscript command. Execute the R script. This is done using the %rscript% “rungf% commands, run in tandem on the same line. Finally, we can create a message that is printed if the script completes execution. We can also and a PAUSE command to the end of the script to keep the command line open after executing. This saves any errors that might have occured, and aids in problem solving. Next, use microsoft scheduler to schedule the running of your .bat file that you just created. And now, Voila!! Providing you don’t hit any errors, you should have an emailed report landing in your email inbox with important datails you decided were important for monitoring your equipment, and the ongoing state of the animals and research project in your care. "],["references.html", "5 References", " 5 References Brennan, Jameson, Ira Parsons, Meredith Harrison, and Hector Menendez. 2024. “Development of an Application Programming Interface (API) to Automate Downloading and Processing of Precision Livestock Data,” February. Parsons, Ira L., Durham A. Norman, Brandi B. Karisch, Stephen L. Webb, Amanda E. Stone, Mike D. Proctor, and Garrett M. Street. 2023. “Automated Walk-over-Weigh System to Track Daily Body Mass and Growth in Grazing Steers.” Computers and Electronics in Agriculture 212 (September): 108113. https://doi.org/10.1016/j.compag.2023.108113. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
